# üéØ MASTER EXAM STUDY PLAN - JAN 4TH, 2025
## DRL + DNN + ML SysOps | Starting 2:00 PM

---

## üìÖ EXAM SCHEDULE

| Time | Subject | Marks | Target |
|------|---------|-------|--------|
| **9:00 AM** | DRL (Deep Reinforcement Learning) | 30 | **20+** |
| **1:00 PM** | DNN (Deep Neural Networks) | 100‚Üí30 | **80+ / 24 scaled** |
| **4:30 PM** | ML System Optimization | 30 | **20+** |

---

## ‚è∞ STUDY SCHEDULE (Starting 2:00 PM, Jan 3rd)

```
üìó 2:00 PM - 4:00 PM: DRL Part 1 (2 hours)
   ‚îî‚îÄ Value Iteration, Q-update with Œ±

‚òï 4:00 PM - 4:15 PM: BREAK (Snack + Walk)

üìó 4:15 PM - 5:30 PM: DRL Part 2 (1.25 hours)
   ‚îî‚îÄ Returns, MC, Quick concepts

üìò 5:30 PM - 7:00 PM: DNN Part 1 (1.5 hours)
   ‚îî‚îÄ Perceptron, Gradient Descent, Softmax

üçΩÔ∏è 7:00 PM - 7:30 PM: DINNER BREAK

üìò 7:30 PM - 8:30 PM: DNN Part 2 (1 hour)
   ‚îî‚îÄ DFNN Forward, Metrics, Code patterns

üìô 8:30 PM - 9:30 PM: ML SysOps Part 1 (1 hour)
   ‚îî‚îÄ Amdahl's Law (CRITICAL - practice 5 problems)

‚òï 9:30 PM - 9:45 PM: BREAK

üìô 9:45 PM - 10:30 PM: ML SysOps Part 2 (45 min)
   ‚îî‚îÄ MapReduce, k-Means, Parameter Server

üìã 10:30 PM - 11:00 PM: Final Formula Review

üò¥ 11:00 PM - 5:30 AM: SLEEP (6.5 hours)

üåÖ 5:30 AM - 8:30 AM: Final revisions before DRL

üìù 9:00 AM: DRL EXAM
üìù 1:00 PM: DNN EXAM  
üìù 4:30 PM: ML SysOps EXAM
```

---

# üî¥ DRL EXAM GUIDE (Target: 20+/30)

## Pattern (from Dec 2025 actual exam)
**4 Questions √ó 7.5 marks = 30 marks**

| Q# | Topic | Marks | Key Skill |
|----|-------|-------|-----------|
| Q1 | RL Basics + Value Iteration | 7.5 | Calculation |
| Q2 | MDP Formulation | 7.5 | Design + Concept |
| Q3 | MAB + Q-Update | 7.5 | Table calculation |
| Q4 | MC + Returns | 7.5 | Return calculation |

## HIGH-YIELD FORMULAS (Memorize!)

### 1. Value Iteration (4 marks likely) ‚≠ê‚≠ê‚≠ê
```
V‚ÇÅ(s) = max_a Œ£ P(s'|s,a) √ó R(s,a,s')  [when V‚ÇÄ = 0]

Example:
Q(Mode_A) = 0.6(1) + 0.4(2) = 1.4
Q(Mode_B) = 1.0(2) = 2.0
V(state) = max(1.4, 2.0) = 2.0
```

### 2. Incremental Q-Update (3 marks likely) ‚≠ê‚≠ê‚≠ê
```
Q_new = Q_old + Œ±(R - Q_old)

For Œ± = 0.5:
Q = 3.5 + 0.5(8 - 3.5) = 3.5 + 2.25 = 5.75
```

### 3. Return Calculation (3.5 marks likely) ‚≠ê‚≠ê‚≠ê
```
Work BACKWARDS from terminal:
G_t = R_{t+1} + Œ≥ √ó G_{t+1}

Example (Œ≥=0.8):
G‚ÇÇ = 3 + 0.8(-1) = 2.2
G‚ÇÅ = 0 + 0.8(2.2) = 1.76
G‚ÇÄ = 2 + 0.8(1.76) = 3.41
```

### 4. Œµ-Greedy Probabilities
```
P(best action) = 1 - Œµ + Œµ/|A|
P(other action) = Œµ/|A|
```

## Quick Concepts
- **MAB vs MDP**: MAB is stateless; MDP has state transitions
- **V(s) vs Q(s,a)**: Model-free needs Q(s,a) to compare actions
- **Episodic**: Has terminal state; Continuing: No end
- **Œ± = 1**: Memoryless (only last reward matters)

---

# üîµ DNN EXAM GUIDE (Target: 80+/100 = 24+/30 scaled)

## Pattern (from actual pattern document)
**5 Questions √ó 20 marks = 100 marks**

| Q# | Topic | Parts | Key Skill |
|----|-------|-------|-----------|
| Q1 | Perceptron | Calc(6) + Linear Sep(4) + Overfitting(5) + Code(5) |
| Q2 | Linear Regression | GD(6) + Code(5) + RMSE(6) + Compare(3) |
| Q3 | Binary Classification | Sigmoid(6) + Code(5) + Metrics(6) + Compare(3) |
| Q4 | Multi-class | Softmax(6) + Code(5) + Metrics(6) + Compare(3) |
| Q5 | DFNN | Forward(6) + Code(5) + Design(6) + Params(3) |

## HIGH-YIELD FORMULAS

### 1. Perceptron Update (6 marks) ‚≠ê‚≠ê‚≠ê
```
z = w‚ÇÄx‚ÇÄ + w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ
≈∑ = sign(z)  ‚Üí  +1 if z‚â•0, else -1
Œîw·µ¢ = Œ∑(target - ≈∑) √ó x·µ¢
```

### 2. Gradient Descent (6 marks) ‚≠ê‚≠ê‚≠ê
```
≈∑ = Xw
e = ≈∑ - y
‚àáJ = (1/N) √ó X·µÄ √ó e
w_new = w - Œ∑ √ó ‚àáJ
```

### 3. Sigmoid + BCE (6 marks) ‚≠ê‚≠ê‚≠ê
```
≈∑ = œÉ(z) = 1/(1 + e^(-z))
BCE = -[y log(≈∑) + (1-y) log(1-≈∑)]
Gradient = (≈∑ - y) √ó x

Key values: œÉ(0)=0.5, œÉ(1)=0.73, œÉ(-1)=0.27
```

### 4. Softmax + CCE (6 marks) ‚≠ê‚≠ê‚≠ê
```
≈∑‚Çñ = e^z‚Çñ / Œ£e^z‚±º
CCE = -log(≈∑_true_class)

Key: e‚Å∞=1, e¬π=2.72, e¬≤=7.39
```

### 5. DFNN Forward Pass (6 marks) ‚≠ê‚≠ê‚≠ê
```
Layer 1: z‚ÅΩ¬π‚Åæ = xW‚ÅΩ¬π‚Åæ + b‚ÅΩ¬π‚Åæ, h‚ÅΩ¬π‚Åæ = ReLU(z‚ÅΩ¬π‚Åæ)
Layer 2: z‚ÅΩ¬≤‚Åæ = h‚ÅΩ¬π‚ÅæW‚ÅΩ¬≤‚Åæ + b‚ÅΩ¬≤‚Åæ, ≈∑ = œÉ(z‚ÅΩ¬≤‚Åæ)
```

### 6. Parameter Count (3 marks)
```
Total = Œ£ n‚Çó(n‚Çó‚Çã‚ÇÅ + 1)
Example 100‚Üí64‚Üí32‚Üí3: 6464 + 2080 + 99 = 8643
```

### 7. Confusion Matrix Metrics (6 marks)
```
Accuracy = (TP + TN) / Total
Precision = TP / (TP + FP)
Recall = TP / (TP + FN)
```

## Code Blanks Pattern
```python
np.ones(...)     # Bias column
np.zeros(...)    # Initialize weights
np.dot(w, x)     # or w @ x - Weighted sum
1/(1+np.exp(-z)) # Sigmoid
np.maximum(0,z)  # ReLU
(y_pred - y)     # Error
```

---

# üü¢ ML SYSOPS EXAM GUIDE (Target: 20+/30)

## HIGH-YIELD FORMULAS

### 1. Amdahl's Law (8-10 marks - GUARANTEED!) ‚≠ê‚≠ê‚≠ê
```
Speedup(p) = 1 / (f + (1-f)/p)
Max Speedup = 1/f

Where:
  f = serial fraction
  p = processors

Example: f=0.2, p=4
Speedup = 1/(0.2 + 0.8/4) = 1/(0.2+0.2) = 1/0.4 = 2.5
```

### Quick Reference
| f | Max Speedup | p=4 | p=8 |
|---|-------------|-----|-----|
| 0.1 | 10 | 3.08 | 4.71 |
| 0.2 | 5 | 2.50 | 3.33 |
| 0.25 | 4 | 2.29 | 2.91 |

### 2. MapReduce (5-6 marks) ‚≠ê‚≠ê
```python
# Word Count
MAP:    emit(word, 1)
REDUCE: return sum(values)

# Average
MAP:    emit(key, (value, 1))
REDUCE: return sum_values / sum_counts
```

### 3. k-Means Parallelization
- **ASSIGN phase**: Embarrassingly parallel (each processor handles subset)
- **UPDATE phase**: Local sums ‚Üí Global reduce ‚Üí New centers

### 4. Parameter Server
- Workers PULL parameters
- Workers compute LOCAL gradients
- Workers PUSH gradients
- Server AGGREGATES and UPDATES

---

## üìã STUDY PRIORITY BY TIME

### 2:00-5:30 PM: DRL (3.5 hours)
| Concept | Time | Practice |
|---------|------|----------|
| Value Iteration | 1.5 hr | Practice Set Q42 |
| Q-update with Œ± | 1 hr | Practice Set Q13, Q17 |
| Returns + MC | 1 hr | Practice Set Q53 |

### 5:30-8:30 PM: DNN (3 hours)
| Concept | Time | Practice |
|---------|------|----------|
| Perceptron table | 40 min | dnn_practice A1 |
| Softmax + CCE | 40 min | dnn_practice D1 |
| GD iteration | 30 min | dnn_practice B1 |
| DFNN forward | 30 min | dnn_practice E1 |
| Metrics | 20 min | dnn_practice C2 |
| Code patterns | 20 min | All B parts |

### 8:30-10:30 PM: ML SysOps (2 hours)
| Concept | Time | Practice |
|---------|------|----------|
| Amdahl's Law | 1 hr | 5 different calculations |
| MapReduce | 30 min | Word count, average |
| k-Means + PS | 30 min | Conceptual review |

---

## üéØ SCORE TARGETS

| Exam | Target | Strategy |
|------|--------|----------|
| **DRL** | 20+/30 | Master 3 calculations (10.5 marks) |
| **DNN** | 80+/100 (24+/30) | All Part A + B + Metrics |
| **ML SysOps** | 20+/30 | Amdahl's Law alone = 10 marks |

---

## üìÅ DOCUMENTS TO READ (In Order)

### üî¥ DRL Documents (Read during 2:00-5:30 PM)

| Priority | File | What to Focus On |
|----------|------|------------------|
| 1Ô∏è‚É£ | **`/sourcecode/DRL_DEC2025_EXAM_ANALYSIS.md`** | Actual exam pattern + solutions |
| 2Ô∏è‚É£ | `/deep-reinforcement-learning/study-materials/drl_practice_problems.md` | Q13, Q17, Q42, Q53 |
| 3Ô∏è‚É£ | `/deep-reinforcement-learning/study-materials/drl_formula_sheet.md` | Quick reference |
| 4Ô∏è‚É£ | `/deep-reinforcement-learning/DRL_regular_dec25_solved.pdf` | Actual exam solutions |

### üîµ DNN Documents (Read during 5:30-8:30 PM)

| Priority | File | What to Focus On |
|----------|------|------------------|
| 1Ô∏è‚É£ | **`/sourcecode/DNN_80PLUS_COMPLETE_GUIDE.md`** | Complete guide with all solutions |
| 2Ô∏è‚É£ | `/deep-neural-networks/study-materials/dnn_practice_problems.md` | Problems A1, B1, C1, D1, E1 |
| 3Ô∏è‚É£ | `/deep-neural-networks/study-materials/dnn_formula_sheet.md` | Quick reference |

### üü¢ ML SysOps Documents (Read during 8:30-10:30 PM)

| Priority | File | What to Focus On |
|----------|------|------------------|
| 1Ô∏è‚É£ | **`/sourcecode/MLSO_EXAM_GUIDE_JAN4.md`** | Amdahl's Law examples |
| 2Ô∏è‚É£ | `/ml-sys-ops/study-materials/mlso_formula_sheet.md` | All formulas |
| 3Ô∏è‚É£ | `/ml-sys-ops/study-materials/mlso_practice_problems.md` | MapReduce examples |

---

## üèÉ QUICK START GUIDE

**Open these 3 files NOW:**
```
1. /sourcecode/MASTER_EXAM_PLAN.md      ‚Üê This file (overview)
2. /sourcecode/DRL_DEC2025_EXAM_ANALYSIS.md  ‚Üê Start DRL here
3. /deep-reinforcement-learning/study-materials/drl_practice_problems.md
```

---

**START NOW! Focus on calculations - they give guaranteed marks! üí™**
